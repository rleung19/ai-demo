{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Churn Model Scoring (Batch Prediction)\n",
        "\n",
        "This notebook scores all users using the trained churn model and stores predictions in CHURN_PREDICTIONS table.\n",
        "\n",
        "## Steps:\n",
        "1. Load trained model from OML Datastore\n",
        "2. Load user features from CHURN_USER_FEATURES view\n",
        "3. Score all users (batch prediction)\n",
        "4. Store predictions in CHURN_PREDICTIONS table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%python\n",
        "\n",
        "# Cell 1: Import and Setup\n",
        "import oml\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import oracledb\n",
        "import os\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Churn Model Scoring (Batch Prediction)\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# Check OML connection\n",
        "if oml.isconnected():\n",
        "    print(\"✓ OML connected\")\n",
        "else:\n",
        "    print(\"⚠️  OML not connected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%python\n",
        "\n",
        "# Cell 2: Load Model from OML Datastore\n",
        "model_name = 'churn_xgboost_v1'\n",
        "\n",
        "print(f\"Loading model '{model_name}' from OML datastore...\")\n",
        "try:\n",
        "    model_dict = oml.ds.load(model_name)\n",
        "    xgb_model = model_dict['model']\n",
        "    print(f\"✓ Model loaded successfully\")\n",
        "    print(f\"  Model type: {type(xgb_model)}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERROR: Failed to load model: {e}\")\n",
        "    print(\"   Make sure you've trained and saved the model first!\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%python\n",
        "\n",
        "# Cell 3: Load User Features\n",
        "print(\"Loading user features from CHURN_USER_FEATURES view...\")\n",
        "user_features_oml = oml.sync(view='CHURN_USER_FEATURES')\n",
        "user_features_pd = user_features_oml.pull()\n",
        "\n",
        "print(f\"✓ Loaded {len(user_features_pd):,} user profiles\")\n",
        "\n",
        "# Get USER_ID and features\n",
        "user_ids = user_features_pd['USER_ID'].copy()\n",
        "feature_cols = [col for col in user_features_pd.columns if col != 'USER_ID']\n",
        "X_users = user_features_pd[feature_cols].copy()\n",
        "\n",
        "print(f\"✓ Features: {len(feature_cols)}\")\n",
        "\n",
        "# Clean data\n",
        "print(\"\\nCleaning data...\")\n",
        "for col in feature_cols:\n",
        "    if pd.api.types.is_numeric_dtype(X_users[col]):\n",
        "        X_users[col] = X_users[col].replace([np.inf, -np.inf], np.nan)\n",
        "        X_users[col] = X_users[col].fillna(0)\n",
        "\n",
        "print(\"✓ Data cleaned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%python\n",
        "\n",
        "# Cell 4: Score Users\n",
        "# Push to OML\n",
        "print(\"Pushing user features to OML...\")\n",
        "X_users_oml = oml.push(X_users)\n",
        "X_users_oml_features = X_users_oml[feature_cols]\n",
        "\n",
        "print(f\"✓ Features pushed: {X_users_oml_features.shape}\")\n",
        "\n",
        "# Get predictions\n",
        "print(\"Generating predictions...\")\n",
        "y_pred_proba_oml = xgb_model.predict_proba(X_users_oml_features)\n",
        "\n",
        "# Convert to pandas\n",
        "y_pred_proba_pd = y_pred_proba_oml.pull()\n",
        "if isinstance(y_pred_proba_pd, pd.DataFrame):\n",
        "    if 1 in y_pred_proba_pd.columns:\n",
        "        churn_probabilities = y_pred_proba_pd[1].values\n",
        "    elif len(y_pred_proba_pd.columns) == 2:\n",
        "        churn_probabilities = y_pred_proba_pd.iloc[:, 1].values\n",
        "    else:\n",
        "        churn_probabilities = y_pred_proba_pd.values.flatten()\n",
        "else:\n",
        "    churn_probabilities = np.array(y_pred_proba_pd)\n",
        "\n",
        "print(f\"✓ Generated {len(churn_probabilities):,} predictions\")\n",
        "print(f\"  Average churn probability: {churn_probabilities.mean():.4f}\")\n",
        "print(f\"  Max churn probability: {churn_probabilities.max():.4f}\")\n",
        "print(f\"  Min churn probability: {churn_probabilities.min():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%python\n",
        "\n",
        "# Cell 5: Store Predictions in Database\n",
        "# Note: This cell requires database connection\n",
        "# You may need to configure connection parameters\n",
        "\n",
        "# Calculate predictions\n",
        "threshold = 0.5\n",
        "predicted_labels = (churn_probabilities >= threshold).astype(int)\n",
        "risk_scores = (churn_probabilities * 100).astype(int).clip(0, 100)\n",
        "model_version = 'churn_xgboost_v1'\n",
        "prediction_date = datetime.now()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Storing Predictions\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Database connection (adjust as needed)\n",
        "# For OML Notebooks, you may need to use oml.connect() or configure connection\n",
        "# This example assumes you have connection configured\n",
        "\n",
        "try:\n",
        "    # Try to get connection from environment or OML\n",
        "    # Adjust this based on your OML Notebooks setup\n",
        "    connection = None  # You'll need to configure this\n",
        "    \n",
        "    if connection is None:\n",
        "        print(\"⚠️  Database connection not configured\")\n",
        "        print(\"   Predictions calculated but not stored\")\n",
        "        print(\"   Configure connection in this cell to store predictions\")\n",
        "    else:\n",
        "        cursor = connection.cursor()\n",
        "        \n",
        "        # Clear existing predictions\n",
        "        try:\n",
        "            cursor.execute(\"TRUNCATE TABLE OML.CHURN_PREDICTIONS\")\n",
        "            print(\"✓ Cleared existing predictions\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️  WARNING: Could not truncate table: {e}\")\n",
        "        \n",
        "        # Insert predictions\n",
        "        print(f\"\\nInserting {len(user_ids):,} predictions...\")\n",
        "        \n",
        "        insert_sql = \"\"\"\n",
        "            INSERT INTO OML.CHURN_PREDICTIONS (\n",
        "                USER_ID,\n",
        "                PREDICTED_CHURN_PROBABILITY,\n",
        "                PREDICTED_CHURN_LABEL,\n",
        "                RISK_SCORE,\n",
        "                MODEL_VERSION,\n",
        "                PREDICTION_DATE\n",
        "            ) VALUES (:1, :2, :3, :4, :5, :6)\n",
        "        \"\"\"\n",
        "        \n",
        "        data_tuples = []\n",
        "        for i in range(len(user_ids)):\n",
        "            data_tuples.append((\n",
        "                str(user_ids.iloc[i]),\n",
        "                float(churn_probabilities[i]),\n",
        "                int(predicted_labels[i]),\n",
        "                int(risk_scores[i]),\n",
        "                model_version,\n",
        "                prediction_date\n",
        "            ))\n",
        "        \n",
        "        cursor.executemany(insert_sql, data_tuples)\n",
        "        connection.commit()\n",
        "        print(f\"✓ Successfully inserted {len(data_tuples):,} predictions\")\n",
        "        \n",
        "        # Verify\n",
        "        cursor.execute(\"SELECT COUNT(*) FROM OML.CHURN_PREDICTIONS\")\n",
        "        count = cursor.fetchone()[0]\n",
        "        print(f\"✓ Verified: {count:,} rows in CHURN_PREDICTIONS table\")\n",
        "        \n",
        "        # Summary statistics\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT \n",
        "                COUNT(*) AS TOTAL,\n",
        "                SUM(CASE WHEN PREDICTED_CHURN_LABEL = 1 THEN 1 ELSE 0 END) AS AT_RISK,\n",
        "                AVG(PREDICTED_CHURN_PROBABILITY) * 100 AS AVG_RISK_SCORE,\n",
        "                AVG(RISK_SCORE) AS AVG_RISK_SCORE_INT\n",
        "            FROM OML.CHURN_PREDICTIONS\n",
        "        \"\"\")\n",
        "        stats = cursor.fetchone()\n",
        "        total, at_risk, avg_prob, avg_risk = stats\n",
        "        \n",
        "        print(f\"\\nPrediction Summary:\")\n",
        "        print(f\"  Total users: {total:,}\")\n",
        "        print(f\"  At-risk users: {at_risk:,} ({at_risk/total*100:.2f}%)\")\n",
        "        print(f\"  Average risk score: {avg_risk:.1f}%\")\n",
        "        \n",
        "        cursor.close()\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ ERROR: Failed to store predictions: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

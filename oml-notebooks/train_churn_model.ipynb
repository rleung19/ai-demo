{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Churn Prediction Model Training\n",
        "\n",
        "This notebook trains a churn prediction model using OML4Py XGBoost.\n",
        "\n",
        "## Steps:\n",
        "1. Load training data from CHURN_TRAINING_DATA view\n",
        "2. Split data into train/test sets\n",
        "3. Train XGBoost model using OML4Py\n",
        "4. Evaluate model performance\n",
        "5. Save model to OML Datastore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%python\n",
        "\n",
        "# Cell 1: Import and Setup\n",
        "import oml\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Churn Prediction Model Training\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# Check OML connection\n",
        "if oml.isconnected():\n",
        "    print(\"✓ OML connected\")\n",
        "else:\n",
        "    print(\"⚠️  OML not connected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%python\n",
        "\n",
        "# Cell 2: Load Training Data\n",
        "\n",
        "# Load data from view\n",
        "print(\"Loading data from CHURN_TRAINING_DATA view...\")\n",
        "train_data_oml = oml.sync(view='CHURN_TRAINING_DATA')\n",
        "train_data_pd = train_data_oml.pull()\n",
        "\n",
        "print(f\"✓ Loaded {len(train_data_pd):,} rows\")\n",
        "print(f\"✓ Columns: {len(train_data_pd.columns)}\")\n",
        "\n",
        "# Check churn distribution\n",
        "churn_rate = train_data_pd['CHURNED'].mean()\n",
        "print(f\"\\nData Quality Check:\")\n",
        "print(f\"  Churn rate: {churn_rate*100:.2f}%\")\n",
        "print(f\"  Churned: {train_data_pd['CHURNED'].sum():,}\")\n",
        "print(f\"  Retained: {(train_data_pd['CHURNED'] == 0).sum():,}\")\n",
        "\n",
        "# Identify feature columns\n",
        "exclude_cols = ['USER_ID', 'CHURNED']\n",
        "feature_cols = [col for col in train_data_pd.columns if col not in exclude_cols]\n",
        "\n",
        "print(f\"\\n✓ Feature columns: {len(feature_cols)}\")\n",
        "print(f\"  Features: {', '.join(feature_cols[:10])}{'...' if len(feature_cols) > 10 else ''}\")\n",
        "\n",
        "# Prepare X and y\n",
        "X_pd = train_data_pd[feature_cols].copy()\n",
        "y_pd = train_data_pd['CHURNED'].copy()\n",
        "\n",
        "# Clean data\n",
        "print(\"\\nCleaning data...\")\n",
        "for col in feature_cols:\n",
        "    if pd.api.types.is_numeric_dtype(X_pd[col]):\n",
        "        X_pd[col] = X_pd[col].replace([np.inf, -np.inf], np.nan)\n",
        "        X_pd[col] = X_pd[col].fillna(0)\n",
        "    elif pd.api.types.is_object_dtype(X_pd[col]):\n",
        "        # Handle categorical columns - convert to numeric if needed\n",
        "        X_pd[col] = pd.Categorical(X_pd[col]).codes\n",
        "\n",
        "# Check for constant columns (no variance)\n",
        "constant_cols = []\n",
        "for col in feature_cols:\n",
        "    if X_pd[col].nunique() <= 1:\n",
        "        constant_cols.append(col)\n",
        "\n",
        "if constant_cols:\n",
        "    print(f\"⚠️  Warning: Found {len(constant_cols)} constant columns: {constant_cols}\")\n",
        "    feature_cols = [col for col in feature_cols if col not in constant_cols]\n",
        "    X_pd = X_pd[feature_cols]\n",
        "    print(f\"  Removed constant columns, using {len(feature_cols)} features\")\n",
        "\n",
        "print(\"✓ Data cleaned\")\n",
        "print(f\"  Final feature count: {len(feature_cols)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%python\n",
        "\n",
        "# Cell 2.5: Data Quality Diagnostics (Optional)\n",
        "# Run this cell if model performance is poor to diagnose issues\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Data Quality Diagnostics\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check feature distributions\n",
        "print(\"\\nFeature Statistics (First 5 Features):\")\n",
        "print(\"-\" * 60)\n",
        "for col in feature_cols[:5]:  # Check first 5 features\n",
        "    if col in X_pd.columns and pd.api.types.is_numeric_dtype(X_pd[col]):\n",
        "        print(f\"\\n{col}:\")\n",
        "        print(f\"  Mean: {X_pd[col].mean():.2f}\")\n",
        "        print(f\"  Std:  {X_pd[col].std():.2f}\")\n",
        "        print(f\"  Min:  {X_pd[col].min():.2f}\")\n",
        "        print(f\"  Max:  {X_pd[col].max():.2f}\")\n",
        "        print(f\"  NaN:  {X_pd[col].isna().sum()}\")\n",
        "    elif col in X_pd.columns:\n",
        "        print(f\"\\n{col}: (non-numeric)\")\n",
        "        print(f\"  Unique values: {X_pd[col].nunique()}\")\n",
        "\n",
        "# Check correlation with target\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Feature-Target Correlations (Top 10)\")\n",
        "print(\"=\" * 60)\n",
        "correlations = []\n",
        "for col in feature_cols:\n",
        "    if col in X_pd.columns and pd.api.types.is_numeric_dtype(X_pd[col]):\n",
        "        try:\n",
        "            corr = X_pd[col].corr(y_pd)\n",
        "            if not np.isnan(corr):\n",
        "                correlations.append((col, abs(corr)))\n",
        "        except Exception:\n",
        "            pass  # Skip if correlation calculation fails\n",
        "\n",
        "if len(correlations) > 0:\n",
        "    correlations.sort(key=lambda x: x[1], reverse=True)\n",
        "    print(\"\\nTop correlated features:\")\n",
        "    for col, corr in correlations[:10]:\n",
        "        print(f\"  {col:30} {corr:.4f}\")\n",
        "    \n",
        "    max_corr = max([c[1] for c in correlations])\n",
        "    if max_corr < 0.1:\n",
        "        print(\"\\n⚠️  WARNING: Very low correlations with target!\")\n",
        "        print(f\"   Maximum correlation: {max_corr:.4f}\")\n",
        "        print(\"   Features may not be predictive of churn.\")\n",
        "        print(\"   This could explain poor model performance.\")\n",
        "    else:\n",
        "        print(f\"\\n✓ Maximum correlation: {max_corr:.4f}\")\n",
        "        if max_corr > 0.3:\n",
        "            print(\"   Good: Some features are strongly correlated with churn\")\n",
        "        elif max_corr > 0.1:\n",
        "            print(\"   Moderate: Features have some predictive power\")\n",
        "else:\n",
        "    print(\"⚠️  WARNING: Could not calculate correlations!\")\n",
        "    print(\"   Check data types and ensure features are numeric\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%python\n",
        "\n",
        "# Cell 3: Split Data\n",
        "# Split into train/test\n",
        "X_train_pd, X_test_pd, y_train_pd, y_test_pd = train_test_split(\n",
        "    X_pd, y_pd,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_pd\n",
        ")\n",
        "\n",
        "print(f\"✓ Train size: {len(X_train_pd):,}\")\n",
        "print(f\"✓ Test size: {len(X_test_pd):,}\")\n",
        "print(f\"✓ Train churn rate: {y_train_pd.mean() * 100:.2f}%\")\n",
        "print(f\"✓ Test churn rate: {y_test_pd.mean() * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%python\n",
        "\n",
        "# Cell 4: Train XGBoost Model\n",
        "# Merge X_train and y_train for database push\n",
        "train_combined_pd = X_train_pd.copy()\n",
        "train_combined_pd['CHURNED'] = y_train_pd.values\n",
        "\n",
        "# Push to database\n",
        "print(\"Pushing training data to OML...\")\n",
        "train_oml = oml.push(train_combined_pd)\n",
        "print(f\"✓ Training data pushed: {train_oml.shape}\")\n",
        "\n",
        "# Get features and target\n",
        "X_train_oml = train_oml[feature_cols]\n",
        "y_train_oml = train_oml['CHURNED']\n",
        "\n",
        "print(f\"✓ X_train_oml shape: {X_train_oml.shape}\")\n",
        "print(f\"✓ y_train_oml shape: {y_train_oml.shape}\")\n",
        "print(f\"✓ Training churn rate: {y_train_oml.mean()*100:.2f}%\")\n",
        "\n",
        "# Verify data quality\n",
        "print(f\"\\nData Quality Check:\")\n",
        "print(f\"  Features with NaN: {sum([X_train_oml[col].isna().any() for col in feature_cols])}\")\n",
        "print(f\"  Features with Inf: {sum([np.isinf(X_train_oml[col]).any() for col in feature_cols])}\")\n",
        "\n",
        "# Create XGBoost model with better hyperparameters\n",
        "print(\"\\nCreating XGBoost model...\")\n",
        "xgb_model = oml.xgb('classification')\n",
        "\n",
        "# Train the model (training happens IN ADB)\n",
        "print(\"Training started...\")\n",
        "print(\"  This may take a few minutes...\")\n",
        "xgb_model = xgb_model.fit(X_train_oml, y_train_oml)\n",
        "print(\"✓ Training completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%python\n",
        "\n",
        "# Cell 5: Evaluate Model\n",
        "# Prepare test data\n",
        "test_combined_pd = X_test_pd.copy()\n",
        "test_combined_pd['CHURNED'] = y_test_pd.values\n",
        "test_oml = oml.push(test_combined_pd)\n",
        "X_test_oml = test_oml[feature_cols]\n",
        "\n",
        "print(f\"✓ Test data prepared: {X_test_oml.shape}\")\n",
        "print(f\"✓ Test churn rate: {y_test_pd.mean()*100:.2f}%\")\n",
        "\n",
        "# Get predictions with supplemental_cols to fix warning\n",
        "print(\"\\nGenerating predictions...\")\n",
        "try:\n",
        "    # Try with supplemental_cols to align predictions\n",
        "    y_pred_proba_oml = xgb_model.predict_proba(\n",
        "        X_test_oml,\n",
        "        supplemental_cols=X_test_oml[feature_cols[:1]]  # Use first feature for alignment\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"⚠️  Warning with supplemental_cols: {e}\")\n",
        "    print(\"   Trying without supplemental_cols...\")\n",
        "    y_pred_proba_oml = xgb_model.predict_proba(X_test_oml)\n",
        "\n",
        "# Convert to numpy\n",
        "y_pred_proba_pd = y_pred_proba_oml.pull()\n",
        "if isinstance(y_pred_proba_pd, pd.DataFrame):\n",
        "    if 1 in y_pred_proba_pd.columns:\n",
        "        y_pred_proba = y_pred_proba_pd[1].values\n",
        "    elif len(y_pred_proba_pd.columns) == 2:\n",
        "        y_pred_proba = y_pred_proba_pd.iloc[:, 1].values\n",
        "    else:\n",
        "        y_pred_proba = y_pred_proba_pd.values.flatten()\n",
        "else:\n",
        "    y_pred_proba = np.array(y_pred_proba_pd)\n",
        "\n",
        "# Check prediction distribution\n",
        "print(f\"\\nPrediction Statistics:\")\n",
        "print(f\"  Mean probability: {y_pred_proba.mean():.4f}\")\n",
        "print(f\"  Min probability: {y_pred_proba.min():.4f}\")\n",
        "print(f\"  Max probability: {y_pred_proba.max():.4f}\")\n",
        "print(f\"  Std probability: {y_pred_proba.std():.4f}\")\n",
        "\n",
        "# If predictions are all the same, model isn't learning\n",
        "if y_pred_proba.std() < 0.01:\n",
        "    print(\"\\n⚠️  WARNING: Predictions have very low variance!\")\n",
        "    print(\"   This suggests the model is not learning from the data.\")\n",
        "    print(\"   Possible issues:\")\n",
        "    print(\"   - Features may not be informative\")\n",
        "    print(\"   - Data quality issues\")\n",
        "    print(\"   - Model needs hyperparameter tuning\")\n",
        "\n",
        "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
        "y_test_vals = y_test_pd.values\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test_vals, y_pred)\n",
        "precision = precision_score(y_test_vals, y_pred, zero_division=0)\n",
        "recall = recall_score(y_test_vals, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test_vals, y_pred, zero_division=0)\n",
        "auc = roc_auc_score(y_test_vals, y_pred_proba)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Model Performance Metrics\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"AUC-ROC:     {auc:.4f} ({auc*100:.2f}%)\")\n",
        "print(f\"Accuracy:    {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"Precision:   {precision:.4f} ({precision*100:.2f}%)\")\n",
        "print(f\"Recall:      {recall:.4f} ({recall*100:.2f}%)\")\n",
        "print(f\"F1 Score:    {f1:.4f}\")\n",
        "\n",
        "# Performance assessment\n",
        "if auc < 0.55:\n",
        "    print(\"\\n⚠️  WARNING: Model performance is very poor (AUC < 0.55)\")\n",
        "    print(\"   This suggests the model is not learning effectively.\")\n",
        "    print(\"   Recommendations:\")\n",
        "    print(\"   1. Check data quality and feature engineering\")\n",
        "    print(\"   2. Verify features are informative\")\n",
        "    print(\"   3. Consider feature selection\")\n",
        "    print(\"   4. Try different hyperparameters\")\n",
        "elif auc < 0.70:\n",
        "    print(\"\\n⚠️  Model performance is below target (AUC < 0.70)\")\n",
        "    print(\"   Consider improving features or hyperparameter tuning\")\n",
        "else:\n",
        "    print(\"\\n✓ Model performance is acceptable (AUC >= 0.70)\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test_vals, y_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(\"                Predicted\")\n",
        "print(\"              Non-Churn  Churn\")\n",
        "print(f\"Actual Non-Churn   {tn:5d}   {fp:5d}\")\n",
        "print(f\"       Churn       {fn:5d}   {tp:5d}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%python\n",
        "\n",
        "# Cell 6: Save Model\n",
        "# Save model to OML datastore\n",
        "model_name = 'churn_xgboost_v1'\n",
        "description = f'Churn prediction XGBoost model - AUC: {auc:.4f}'\n",
        "\n",
        "try:\n",
        "    oml.ds.save(\n",
        "        {'model': xgb_model},\n",
        "        model_name,\n",
        "        description=description,\n",
        "        overwrite=True\n",
        "    )\n",
        "    print(f\"✓ Model saved to OML datastore: {model_name}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERROR: Failed to save model: {e}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
